{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import picamera\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import threading\n",
    "import queue\n",
    "import io\n",
    "import IPython\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    '''\n",
    "    Function to display an image within a Jupyter notebook.\n",
    "    '''\n",
    "    f = io.BytesIO()\n",
    "    Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue(), width = 480, height = 360))\n",
    "\n",
    "def resizeNPArray(array, width, height):\n",
    "    '''\n",
    "    Function to resize a given numpy array to another width/height,\n",
    "    whilst preserving the relative information - used for images.\n",
    "    '''\n",
    "    img = Image.fromarray(array)\n",
    "    img = img.resize((width, height), Image.ANTIALIAS)\n",
    "    resized = np.asarray(img)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFacesAndEyes(img_array):\n",
    "    '''\n",
    "    Function to detect eyes and faces using a Haar-Cascade classifier.\n",
    "    '''\n",
    "    gray = cv.cvtColor(img_array, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv.rectangle(img_array,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img_array[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "\n",
    "class ImageProcessor(threading.Thread):\n",
    "    '''\n",
    "    Thread-safe class to process a stream of jpeg sequences from a given queue.\n",
    "    '''\n",
    "    def __init__(self, thread_stopper, frames, lock):\n",
    "        '''\n",
    "        thread_stopper -> Is the event which stops the thread when set.\n",
    "        frames -> The queue from which jpeg images come (in numpy.array format).\n",
    "        lock -> Mutex for the queue.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.thread_stopper = thread_stopper\n",
    "        self.frames = frames\n",
    "        self.lock = lock\n",
    "        self.incoming = np.empty((240, 320, 3), dtype = np.uint8)\n",
    "        self.processed = np.zeros((240, 320, 3), dtype = np.uint8)\n",
    "        \n",
    "        self.verticals = np.array(80 * [np.arange(0, 60)]).T\n",
    "        self.verticals = self.verticals[:,:,np.newaxis]\n",
    "        \n",
    "        self.horizontals = np.array(60 * [np.arange(0, 80)])\n",
    "        self.horizontals = self.horizontals[:,:,np.newaxis]\n",
    "        \n",
    "    def run(self):\n",
    "        '''\n",
    "        Main thread which runs indefinitely until <<thread_stopper>> event is set.\n",
    "        This function processes each incoming image from the queue iteratively and then displays it in this notebook.\n",
    "        '''\n",
    "        while not thread_stopper.is_set():\n",
    "            try:\n",
    "                self.lock.acquire()\n",
    "                self.incoming = self.frames.get_nowait()\n",
    "                self.position, self.processed = self.dowork(self.incoming)\n",
    "                self.frames.task_done()\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            finally:\n",
    "                self.lock.release()\n",
    "            showarray(self.processed)\n",
    "            IPython.display.clear_output(wait = True)\n",
    "            \n",
    "    def dowork(self, array):\n",
    "        '''\n",
    "        array -> Is a numpy array that holds the a RGB image.\n",
    "        Function to process an image and detect spots of a given targeted color.\n",
    "        '''\n",
    "        \n",
    "        # down-sizing the image and running KMeans on it\n",
    "        output = array.copy()\n",
    "        array = resizeNPArray(array, 80, 60)\n",
    "        image_and_positions = np.concatenate((array, self.verticals, self.horizontals), axis = 2)\n",
    "        reshaped = image_and_positions.reshape((60 * 80, 5))\n",
    "        kmeans = KMeans(n_clusters = 6,\n",
    "                       n_init = 1,\n",
    "                       max_iter = 300,\n",
    "                       precompute_distances = True).fit(reshaped)\n",
    "        rgb_centers = kmeans.cluster_centers_[:, 0:3]\n",
    "        \n",
    "        labels_rgb = np.empty((4800, 3))\n",
    "        for i in range(6):\n",
    "            labels_rgb[kmeans.labels_ == i] = rgb_centers[i]\n",
    "        labels_rgb = labels_rgb.reshape((60, 80, 3)).astype(np.uint8)\n",
    "        \n",
    "        # getting the closest KMeans center to the targeted color\n",
    "        diff = rgb_centers - target_color\n",
    "        closest = np.sqrt(np.power(diff, 2).sum(axis = 1))\n",
    "        closest_label = closest.argmin()\n",
    "        \n",
    "        # determining the distribution of the targeted pixels\n",
    "        # (the target pixels are identified with the label of the selected KMeans center)\n",
    "        labels = kmeans.labels_.reshape((60, 80))\n",
    "        labels = labels == closest_label\n",
    "        sum_labels_vertical = labels.sum(axis = 1)\n",
    "        sum_labels_horizontal = labels.sum(axis = 0)\n",
    "        \n",
    "        # 4800 = 60 * 80 pixels\n",
    "        if not sum_labels_vertical.sum() > color_threshold * 4800:\n",
    "            return (None, output)\n",
    "        \n",
    "        # find the countour of the spot of color\n",
    "        non_zero_elements = np.nonzero(sum_labels_vertical)\n",
    "        # multiply by 4 to get to the original size\n",
    "        min_vertical = np.min(non_zero_elements) * 4\n",
    "        max_vertical = np.max(non_zero_elements) * 4\n",
    "        non_zero_elements = np.nonzero(sum_labels_horizontal)\n",
    "        min_horizontal = np.min(non_zero_elements) * 4\n",
    "        max_horizontal = np.max(non_zero_elements) * 4\n",
    "        \n",
    "        # and then draw a rectangle around the detected spot of color\n",
    "        output[min_vertical:max_vertical+1,min_horizontal,:] = border_color\n",
    "        output[min_vertical:max_vertical+1,max_horizontal,:] = border_color\n",
    "        output[min_vertical,min_horizontal:max_horizontal+1,:] = border_color\n",
    "        output[max_vertical,min_horizontal:max_horizontal+1,:] = border_color\n",
    "        \n",
    "        center_position = (min_vertical + max_vertical) / 2\n",
    "                \n",
    "        return (center_position, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = queue.Queue(maxsize = 10)\n",
    "thread_stopper = threading.Event()\n",
    "lock = threading.Lock()\n",
    "target_color = np.array([255, 255, 255]) # white\n",
    "border_color = np.array([0, 255, 0]) # green\n",
    "color_threshold = 0.07 # in percentage\n",
    "time_to_run = 5 # in seconds\n",
    "\n",
    "start = time.time()\n",
    "imageThread = ImageProcessor(thread_stopper, frames, lock)\n",
    "imageThread.start()\n",
    "\n",
    "with picamera.PiCamera() as camera:\n",
    "    camera.resolution = (320, 240)\n",
    "    camera.framerate = 30\n",
    "    while time.time() - start < time_to_run:\n",
    "        freshest_frame = np.empty((240, 320, 3), dtype = np.uint8)\n",
    "        camera.capture_sequence([freshest_frame], use_video_port = True, format = 'rgb')\n",
    "        lock.acquire()\n",
    "        if frames.full():\n",
    "            frames.get()\n",
    "            frames.task_done()\n",
    "        else:\n",
    "            frames.put(freshest_frame)\n",
    "        lock.release()\n",
    "print(\"picamera session ended\")\n",
    "\n",
    "thread_stopper.set()\n",
    "print(\"triggered image processing thread\")\n",
    "\n",
    "imageThread.join()\n",
    "print(\"thread joined\")\n",
    "\n",
    "with picamera.PiCamera() as camera:\n",
    "    camera.resolution = (320, 240)\n",
    "    camera.framerate = 30\n",
    "    freshest_frame = np.empty((240, 320, 3), dtype = np.uint8)\n",
    "    while True:\n",
    "        camera.capture(freshest_frame, use_video_port = True, format = 'rgb')\n",
    "        detectFacesAndEyes(freshest_frame)\n",
    "        showarray(freshest_frame)\n",
    "        IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
